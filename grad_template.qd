.docname {卒業論文見本}
.doctype {paged}
.doclang {Japanese}
.theme {paperwhite} layout:{latex}

.pageformat size:{a4} margin:{1.5cm}
.pagemargin {bottomcenter}
    .text{}
.css
    .quarkdown h1 {font-size: 1.5rem !important;}
    .quarkdown h2 {font-size: 1.3rem !important;}
    .quarkdown h3 {font-size: 1.15rem !important;}
    .quarkdown h4 {font-size: 1.05rem !important;}
    /* Cross-reference: show Japanese style for section references */
    /* Top-level sections (no dot): 第1章 */
    .quarkdown .cross-reference[data-localized-kind="セクション"][data-location]:not([data-location*="."])::before {
        content: "第" attr(data-location) "章" !important;
    }
    /* Sub-sections (has dot): 第2.1節 */
    .quarkdown .cross-reference[data-localized-kind="セクション"][data-location*="."]::before {
        content: "第" attr(data-location) "節" !important;
    }
    .textcenter {
        text-align: center;
    }

.var {author} {田代 圭梧}
.var {affiliation} {龍谷大学先端理工学部 数理・情報科学課程}
.var {id} {Y220010}
.var {maintitle} {Notionデータを対象とした  
                    ベクトル検索システム  
                    「NotionFinder」の開発}
.var {subtitle}  {}

<!-- ナンバリング -->
.numbering
    - headings: 1.1
    - equations: (1.1)
    - figures: 1.1
    - tables: 1.1
    - citations: 1.1

<!-- タイトルページ -->
.function {titlepage}
    .whitespace height:{5cm}
    .column cross:{center}
        .text {2026年度 卒業論文}
        .whitespace height:{10mm}
        .text {.maintitle} size:{large} weight:{bold} classname:{textcenter} 
        .text {.subtitle::otherwise {}} size:{normal}
    .whitespace height:{10cm}
    .column cross:{center} gap:{3mm}
        .text {.affiliation}
        .text {.id .author}
        .text {指導教員 佐野 彰}
    
<!-- 概要ページ -->
.function {abstractpage}
    abstract:
    .column cross:{center}
        .text {2026年度 卒業論文} size:{normal}
        .whitespace height:{5mm}
        .text {.maintitle} size:{large} weight:{bold} classname:{textcenter}
        .text {.subtitle::otherwise {}}
    .column cross:{end}
        .text {.affiliation}
        .text {.id .author}
        .text {指導教員 佐野 彰}
    .column cross:{center}
        .text {概要} size:{normal} weight:{bold}
    .abstract
    <<<
<!-- ここから論文データ -->
<!-- 概要 -->
.var {abstract}
    まだ
     <!-- 段落は空白行で -->
    書かない
.abstractpage {.abstract}

<!-- タイトルページ（ページ番号なし） -->
.titlepage

<!-- 目次（ページ番号なし） -->
.tableofcontents maxdepth:{2} includeunnumbered:{true} <!-- includebibliography:{true} -->

<!-- 4ページ目以降: 本文（ページ番号1から開始） -->
# はじめに {#sec:intro}
.resetpagenumber
.pagemargin {bottomcenter}
    .currentpage


## 研究背景
### Notionの普及と情報量の増大
近年、個人のタスク管理から企業のナレッジ共有に至るまで、クラウドベースのコラボレーションツールの利用が急速に拡大している。
中でも Notion Labs Inc. が提供する「Notion」は、ドキュメント作成、データベース管理、タスク管理などを一元化できる「オールインワン・ワークスペース」として、世界中で多くのユーザーを獲得している .cite{NotionAbout}。
Notion の柔軟なデータベース機能は、ユーザーによる自由度の高い情報蓄積を可能にする一方で、長期的な運用に伴いワークスペース内のデータ量は膨大かつ複雑化する傾向にある。

### 既存検索機能の課題
蓄積された膨大なデータから必要な情報にアクセスするためには、効率的な検索機能が不可欠である。
しかし、Notion に標準搭載されている検索機能は、基本的にキーワードマッチング（字句検索）に基づいている。
この手法は、クエリとドキュメント内の単語が完全に一致する場合においては有効であるが、同義語や表記揺れ、あるいは文脈的な意味の類似性を考慮することはできないという問題を抱えている。
そのため、ユーザーは正確なキーワードを記憶していなければ目的の情報に辿り着けず、情報の再利用性が著しく低下するという課題がある。

### Notion AI の制約
こうした課題に対し、Notion は大規模言語モデル（LLM）を活用した「Notion AI」を導入し、自然言語による質問応答機能を提供している .cite{NotionAI}。
しかし、Notion AI を制限なく利用するには追加のコストが発生するため、全てのユーザーにとって導入が容易なわけではない。
さらに重要な課題として、Web共有（外部公開）における制約が挙げられる。
Notion AI は基本的にログインユーザーのワークスペース内での利用を前提としており、Notionで構築したナレッジベースをWebサイトとして外部公開し、そこで不特定多数の訪問者にAI検索を提供するといった柔軟な運用は困難である。

## 本研究の目的
本研究では、Notion 内に蓄積されたデータを対象とし、文脈や意味に基づいた検索（セマンティック検索）を可能にするWebプラットフォーム「NotionFinder」の設計および開発を行う。
具体的には、Notionから取得したデータをベクトル化し、ユーザーの検索クエリとの意味的な類似度を計算することで、キーワードが完全に一致しなくとも関連性の高いドキュメントを抽出するシステムを構築する。

本研究の主な目的は以下の2点である。

1.  **セマンティック検索の実現**：キーワード検索では拾いきれない、文脈や意図を汲んだ検索体験を提供し、情報の再利用性を向上させること。
2.  **Web共有可能な検索基盤の構築**：Notion 本体の認証や有料プランの制約に依存せず、外部公開されたWebアプリケーション上で、安価かつ高速に高度な検索機能を利用可能にすること。

次章以降では、関連技術の解説、NotionFinder のシステム設計、および実装と評価について述べる。

# NotionFinderのシステム概要 {#sec:method}

!(50%)[Quarkdown](image/systemOverview.png "NotionFinderのシステム概要") {#fig:systemOverview}

.ref {fig:systemOverview} は NotionFinder のシステム概要である。
本システムは、Notionからデータを抽出し検索可能な形式に変換する「前処理パイプライン（ローカル環境）」と、構築されたインデックスを用いてユーザーに検索機能を提供する「Webアプリケーション実行環境」の2層から構成される。
## 前処理パイプライン
検索の基盤となるデータの準備は、以下のフローで行われる。

**Notionデータ取得**  
-  Notionが提供する外部連携用インターフェースを利用し、Notionデータを取得する。

**ベクトル化およびインデックス作成処理**  
-  取得したテキストデータを、埋め込みモデルを用いて高次元のベクトルデータへ変換する。変換されたベクトル群は、高速な類似度検索を可能にするためのインデックスファイルとして構造化・保存される。

**デプロイ**  
-  ローカル環境で構築されたインデックスファイルを、Webアプリケーション実行環境へ配置する。
## Webアプリケーション実行環境
ユーザーによる検索リクエストは、Webアプリケーション実行環境上で以下の手順で処理される。

**検索クエリのベクトル化**  
-  ユーザーが入力した自然言語による検索クエリを、インデックス構築時と同一のモデルを用いてサーバーサイドでベクトル化する。

**インデックスのロード**  
-  配置済みのインデックスデータをサーバーサイドのメモリ上にロードし、検索可能な状態に展開する。

**類似度比較および抽出**  
-  クエリベクトルとインデックス内の各ベクトルとの間で類似度計算を行い、意味的な関連性が高い上位のドキュメントを抽出する。

**検索結果の表示**  
-  抽出された結果に基づき、該当するNotionページのデータ、およびNotionのオリジナルのページへのリンクをユーザーのブラウザ上に表示する。

# 技術スタック {#sec:techstack}

## アプリケーション基盤
**TypeScript**
- 本システムの主要な開発言語として採用した。静的型付けにより、開発段階でのエラー検知やコードの保守性を向上させている。特に、Notion API から取得する複雑な入れ子構造を持つデータを扱う際、厳密な型定義を行うことでデータ処理の安全性を担保している。

**Node.js**
サーバーサイド JavaScript の実行環境として採用した。Web アプリケーションのサーバーサイド処理だけでなく、ローカル環境における前処理パイプラインの実行基盤としても使用している。

**Next.js (App Router)**
- Webアプリケーションのフレームワークには、React ベースの Next.js を採用した。サーバーサイドでのデータ処理とクライアントサイドのインタラクションを統合的に扱えるため、検索クエリの処理や結果表示を効率的に実装可能である。

**GitHub**
- ソースコードのバージョン管理およびホスティングサービスとして採用した。AWS Amplify と連携し、リモートリポジトリへの変更（プッシュ）をトリガーとしてビルドおよびデプロイプロセスを自動的に開始する、CD パイプラインの起点としての役割を担っている。

**AWS Amplify**
- アプリケーションのホスティングおよび CD（継続的デリバリー）環境として採用した。GitHub 上のリポジトリと同期し、ソースコードの更新に合わせて自動的に本番環境への反映を行うパイプラインを構築している。

## 検索・ベクトル処理エンジン
**Xenova (transformers.js)**
- 自然言語のベクトル化（Embedding）を行うためのライブラリとして採用した。通常、Transformer モデルの推論には Python 環境が必要となるが、本ライブラリを用いることで、Next.js が動作する Node.js 環境上で直接、かつ高速にベクトル化処理を実行可能とした。

**HNSWLib (hnswlib-node)**
- HNSW (Hierarchical Navigable Small World) アルゴリズムを実装したライブラリである。本ライブラリは C++ で記述されたコアエンジンの Node.js 向けネイティブバインディングとなっており、JavaScript の実行オーバーヘッドを回避した高速なベクトル演算が可能である。これにより、数千件規模のデータセットに対しても計算コストを抑えた効率的な検索を実現している。

## Notionデータ取得
**Notion API** 検索対象となるNotionデータを取得するために、Notion 公式のインターフェースを使用した。

# システム詳細 {#sec:systemdetail}

## 前処理パイプライン

### 前処理パイプライン全体像
!(100%)[Quarkdown](image/preprocessingPipeline.png "前処理パイプラインの全体処理フロー") {#fig:preprocessingPipeline}

.ref {fig:preprocessingPipeline} に、本システムにおける前処理パイプラインの全体フローを示す。
このパイプラインは、Notion 上の非構造化データをセマンティック検索可能な形式へ変換し、Web アプリケーションとして公開するまでの**データの取得から加工、保存に至る一連の処理**を担うものである。
処理は主にローカル開発環境上で実行され、以下の4つの主要なフェーズで構成される。

1. **Notion APIを用いたNotionデータ取得**
   Notion API を介して、指定されたデータベース内の全ページおよびブロック情報を再帰的に取得する。同時に、画像のリンク切れを防ぐため、メディアファイルのダウンロードとパスの書き換えを行い、永続化された静的アセットとして保存する。

2. **埋め込みベクトルの生成**
   取得したテキストデータを、ローカル環境上の軽量機械学習モデル（Xenova/multilingual-e5-small）に入力し、各ブロックの意味を表す高次元ベクトル（384次元）へ変換する。

3. **インデックスの構築戦略と最適化**
   生成されたベクトル群を、HNSW アルゴリズムを用いて高速検索可能なグラフ構造（インデックス）として構築し、メタデータと共に静的ファイル（JSONおよびバイナリ形式）として出力する。

4. **Amplifyへの更新データのデプロイ**
   生成されたインデックスファイルおよび静的アセットを Git リポジトリへコミット・プッシュする。これをトリガーとして AWS Amplify の CI/CD パイプラインが起動し、最新の検索データが本番環境へ自動的に反映される。

次節より、各フェーズにおける技術的な詳細と実装上の工夫について述べる。

### 実行プロセスの自動化
本システムの前処理パイプラインは、複数の処理（データ取得、画像保存、ベクトル化、インデックス生成）が依存関係を持って順序通りに実行される必要がある。
手動実行によるオペレーションミスを防ぐため、これらの工程を `GNU Make` を用いて自動化している。
開発者はローカル環境で単一のコマンド（`make update-data`）を実行するだけで、Notion からの最新データ取得から Git へのプッシュまでの一連のフロー（.ref {fig:preprocessingPipeline} の Flow: 1〜12）を完結できる設計とした。

### Notion APIを用いたNotionデータ取得

#### Notion SDK の活用と型安全性
Notion API との通信実装には、公式 JavaScript クライアントライブラリである `@notionhq/client` (v2.3.0) を採用した。
本ライブラリは、`search` や `blocks.children.list` といった各エンドポイントへのアクセスをメソッドとして抽象化しているほか、API レスポンスに対する厳密な TypeScript 型定義（`BlockObjectResponse`, `NotionPageData` 等）を提供している。
これにより、開発時には静的な型チェックが可能となり、複雑なプロパティを持つ Notion オブジェクトを扱う際の実行時エラーを未然に防いでいる。

#### 階層構造データの再帰的取得
Notion のページデータは「ブロック」と呼ばれる単位で構成されており、各ブロックはさらに子ブロックを持つことができる（例：リストの中にさらにリストがある、トグルの中に画像がある等）。このため、単一の API リクエストではページ内の全情報を取得できない場合がある。

本システムでは、この入れ子構造に対応するため、深さ優先探索（Depth-First Search）に基づいた再帰的なデータ取得アルゴリズムを実装した。
具体的には、ブロック情報の取得時に `has_children` プロパティを確認し、子要素が存在する場合は再帰的に `blocks.children.list` エンドポイントを呼び出す。これにより、深層にネストされたコンテンツも含めた、ドキュメントの完全なテキスト抽出を実現している。

#### APIレート制限への対応
大量のブロックを再帰的に取得する際、課題となるのが API のリクエスト制限（Rate Limits）である。
Notion API の公式仕様では平均して秒間 3 リクエスト程度が上限とされており、これを超過すると HTTP 429 (Too Many Requests) エラーが返却され、処理が中断してしまう。

前処理パイプラインでは数千規模のブロックを短時間で処理する必要があるため、単純なループ処理では即座に制限に抵触する。
この課題に対し、本実装では API コール間に一定の待機時間（Sleep）を挿入する制御機構を導入した。
実験的な調整の結果、待機時間を `350ms`（約 2.85 リクエスト/秒）に設定することで、API 制限を回避しつつ、実用的な時間内での全量データ同期を可能とした。実装の一部を .ref {code:ratelimit} に示す。

```typescript "コード 4.1: レート制限を考慮したデータ取得ロジック（抜粋）" {#code:ratelimit}
// レート制限対応のための待機時間（約2.85リクエスト/秒に制限）
const RATE_LIMIT_DELAY_MS = 350;

/**
 * 指定時間だけ処理をブロックするユーティリティ関数
 */
async function sleep(ms: number): Promise<void> {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

// ページごとの処理ループ（概念コード）
for (const result of response.results) {
  if (result.object === "page") {
    // ページ内容の取得（内部で再帰的にブロックを取得）
    const pageData = await getPageContent(result.id);
    
    if (pageData) {
      pages.push(pageData);
    }
    
    // APIレート制限（HTTP 429）回避のため、リクエスト間に待機時間を挿入
    await sleep(RATE_LIMIT_DELAY_MS);
  }
}
```

#### メディアファイルの永続化とリンクの書き換え
Notion API が返却する画像や添付ファイル（PDF等）の URL は、Amazon S3 の署名付き URL（Signed URL）であり、セキュリティ上の理由から一定時間（通常1時間程度）で有効期限が切れる仕様となっている。
そのため、取得した URL をそのままデータベースに保存し Web アプリケーションで使用すると、時間の経過とともにリンク切れが発生し、画像が表示されなくなるという致命的な問題がある。

この課題を解決するため、本システムの前処理パイプラインでは、テキストデータの取得と並行してメディアファイルのダウンロード処理を実装した。
具体的には、再帰的なブロック探索の過程で `image`、`pdf`、`file` といったバイナリデータを含むブロックを検知した場合、以下の処理を自動的に実行する。

1.  **データのダウンロード**:
    取得した一時 URL にアクセスし、バイナリデータをストリームとして取得する。
2.  **静的ディレクトリへの保存**:
    取得したデータを、Next.js が静的アセットとして配信可能な `public/images` および `public/files` ディレクトリに保存する。
3.  **参照パスの書き換え**:
    ブロックデータ内の URL プロパティを、Notion の一時 URL から、保存したローカルファイルへのパス（例: `/images/pageId_blockId.png`）へと書き換える。

この処理により、Notion 側の URL 有効期限に依存することなく、アプリケーション上で永続的にメディアを表示することを可能にした。実装の一部を .ref {code:media_download} に示す。

```typescript "コード 4.2: メディアファイルのダウンロードとパス書き換え処理（抜粋）" {#code:media_download}
// メディアタイプごとの保存設定（種別、保存先ディレクトリ、配信パス）
const mediaCases = [
  { type: "image", key: "imageUrl", dir: imagesDir, base: "/images" },
  { type: "pdf",   key: "pdfUrl",   dir: filesDir,  base: "/files"  },
  { type: "file",  key: "fileUrl",  dir: filesDir,  base: "/files"  },
];

for (const c of mediaCases) {
  // ブロックタイプが一致し、かつURLが存在する場合
  if (block.type === c.type && block[c.key]) {
    const url = block[c.key];
    // 一意なファイル名を生成（ページID_ブロックID）
    const filename = `${pageId}_${block.id}${ext}`;
    const filepath = path.join(c.dir, filename);

    // 1. バイナリデータをローカルのpublicディレクトリへダウンロード
    await downloadImageOrFile(url, filepath);

    // 2. ブロック内のURLをローカルパス（静的アセット）に書き換え
    block[c.key] = `${c.base}/${filename}`;
  }
}
```

### 埋め込みベクトルの生成
Notion から取得したテキストデータを検索可能な状態にするためには、自然言語の意味を数値の列（ベクトル）に変換する「埋め込み（Embedding）」処理が必要となる。本節では、採用したモデルの選定根拠および実装詳細について述べる。

#### ベクトル化ライブラリの採用
本システムでは、Python 環境に依存せず Node.js 環境上で直接機械学習モデルを推論させるため、Hugging Face 社が提供する `transformers.js` ライブラリを採用した。
これにより、Next.js のサーバーサイド処理およびローカルの前処理スクリプトと、推論エンジンを同一言語（TypeScript/JavaScript）で統合することが可能となり、システムの複雑性を低減している。

#### 実装上の工夫
モデルの実装にあたり、精度向上とパフォーマンス最適化のために以下の工夫を取り入れた。
##### ベクトル化の粒度と対象データの選別
Notion のデータ構造は、ページ（Page）とそれを構成するブロック（Block）の階層構造となっている。本システムでは、ベクトル化の粒度を「ページ単位」ではなく「ブロック単位」に設定した。
これには以下の2つの理由がある。

1.  **トークン制限の回避**
    採用した `multilingual-e5-small` モデルの最大入力長は 512 トークンである。ページ全体のテキストを一度にベクトル化しようとすると、長文のページでは末尾のデータが切り捨てられ、検索対象から漏れるリスクがある。ブロック単位であれば、この制限内に収まる確率が極めて高くなる。

2.  **検索精度の向上**
    ページ全体を一つのベクトルに集約すると、多様なトピックが含まれる場合にベクトルの特徴が希釈されてしまう。ブロック単位でベクトル化することで、ユーザーの質問に対してピンポイントな回答を含む段落を正確に抽出することが可能となる。

また、Notion のブロックには画像（image）や区切り線（divider）、空行など、テキスト情報を含まない種別も多数存在する。これらは意味的な検索においてノイズとなるため、本システムでは `paragraph`、`heading`（見出し）、`list_item`（リスト）といったテキストプロパティを保持するブロックタイプのみをフィルタリングし、テキストが存在するブロックのみを個別に抽出してベクトル化処理を行った。

##### 推論パラメータの設定と計算効率化
`transformers.js` のパイプライン実行時には、以下のオプションを指定することで出力ベクトルの品質と検索効率を最適化している。

1.  **平均プーリング (Mean Pooling)**
    Transformer モデルの出力は、トークン（単語の一部）ごとのベクトル列である。これを文全体の意味を表す単一の固定長ベクトル（768次元や384次元）に変換するため、`pooling: "mean"` を指定し、全トークンベクトルの平均値を算出している。これにより、文の長さに関わらず一貫したベクトル表現が得られる。

2.  **正規化 (Normalization)**
    `normalize: true` を指定することで、生成されたベクトルに対して 正規化を適用し、そのノルム（長さ）が常に 1 となる単位ベクトルに変換している。
    この処理は、後段の類似度検索において計算コストを削減するために重要である。コサイン類似度 $ S_C(A, B) $ は以下の式 .ref {eq:cosine} で定義される。

    $ S_C(A, B) = \frac{A \cdot B}{\|A\| \|B\|} $ {#eq:cosine}

    ここで、ベクトル $ A, B $ が正規化されている（$ \|A\| = 1, \|B\| = 1 $）場合、分母は 1 となり、式は単純な内積（ドット積）計算へと簡略化される .ref {eq:dot}。

    $ S_C(A, B) = A \cdot B $ {#eq:dot}

    これにより、検索時に都度ノルム計算や除算を行う必要がなくなり、特に大規模なインデックスに対する検索速度の向上に寄与している。

##### クエリとパッセージの区別
採用した E5 モデルは、入力テキストに対して特定のプレフィックス（接頭辞）を付与することで精度が最適化されるよう設計されている。
本システムでは、検索クエリには `"query: "`、検索対象となるドキュメント（Notionデータ）には `"passage: "` を自動的に付与してベクトル化を行うロジックを実装した。

#### 埋め込みモデルの比較選定と性能検証
本システムにおける埋め込みモデルの選定にあたり、多言語対応モデルとして評価の高い `multilingual-e5` シリーズ（Small, Base, Large）を候補とした。
採用するライブラリ `transformers.js` は、Web 実行環境向けに最適化（INT8量子化）されたモデルを提供しており、各モデルのファイルサイズは以下の通りである。

* **Small**: `intfloat/multilingual-e5-small` (約 118MB)
* **Base**: `intfloat/multilingual-e5-base` (約 278MB)
* **Large**: `intfloat/multilingual-e5-large` (約 1.1GB)

##### 実行環境における制約（メモリとコールドスタート）
##### 実行環境における制約（メモリとコールドスタート）
本システムは AWS Amplify を用いたサーバーレス環境（AWS Lambda 等）での稼働を前提としている。
AWS Amplify Hosting のデフォルト設定では、Next.js (SSR) 実行環境のメモリ割り当て上限は **1024MB** である。

この環境下では、機械学習モデルの重みだけでなく、Node.js ランタイム、Next.js フレームワークのオーバーヘッド、およびインデックスデータのメモリ展開に必要なリソースをすべて合計した物理メモリ使用量（RSS）が、この上限内に収まる必要がある。
実環境へのデプロイを行い、メモリ使用状況を計測したログデータを解析した結果、以下の事実が判明した。

1.  **Smallモデルでの限界**
    最も軽量な `multilingual-e5-small` を採用した場合でも、モデルのロードおよびインデックスの展開処理直後のメモリ使用量は **933.42MB** に達した。これは割り当て上限（1024MB）の **91.2%** を占有しており、余剰リソースはわずか 90MB 程度である。

2.  **Base/Largeモデルの不可能性**
    一つ上のサイズである `multilingual-e5-base` は、Small モデルと比較してファイルサイズだけで約 160MB 増加する。
    単純計算でも $933\text{MB} + 160\text{MB} \approx 1093\text{MB}$ となり、アプリケーション本体のメモリ消費と合算すると確実に上限を超過する。

これにより、メモリ不足（Out of Memory）によるプロセス強制終了を回避し、安定稼働を実現するためには、**Small モデルが唯一の選択肢**であることが定量的に示された。
##### 検索精度の実証実験
前述の通り、運用環境の物理的制約から `multilingual-e5-small` が唯一の選択肢となるが、パラメータ数の削減によって検索精度、特に専門的な技術概念の識別能力が損なわれていないかを検証する必要がある。
そこで、キーワードが共通しており、文脈による判別が必要な技術用語を対象とした小規模なベンチマークを実施した。

**1. 実験設定**
以下の2つのトピックについて、類似するが異なる概念を持つドキュメントペアと、それらを区別するための検索クエリを用意した。
* **Gitの統合手法**: `Merge`（履歴を残す）と `Rebase`（履歴を書き換える）
* **ブラウザストレージ**: `LocalStorage`（永続的）と `SessionStorage`（一時的）

具体的には、本システムが**Notionのブロック（Block）単位**でデータを管理・検索していることを踏まえ、ページ全体のような長文ではなく、単一の段落やリストアイテムに相当する以下の短いテキストデータをインデックスに登録した。

1. **Git Mergeに関するブロックデータ ($doc\_1$)**
- 「Git Mergeは、分岐したブランチの履歴をそのまま残し、新しいコミットを作って統合する方法です。過去の経緯が詳細に残ります。」

2. **Git Rebaseに関するブロックデータ ($doc\_2$)**
- 「Git Rebaseは、分岐元の履歴を書き換え、ブランチが一本になるように統合する方法です。履歴は綺麗になりますが元の経緯は消えます。」

3. **LocalStorageに関するブロックデータ ($doc\_3$)**
- 「LocalStorageは、ブラウザに保存されるデータで、サーバーへは自動送信されません。明示的に消さない限り、ウィンドウを閉じても永続的に残ります。」

4. **SessionStorageに関するブロックデータ ($doc\_4$)**
- 「SessionStorageは、ブラウザに保存されるデータですが、タブやウィンドウを閉じると即座に削除されます。サーバーへは送信されません。」

これらのドキュメントに対し、**ユーザーの検索意図を反映したクエリ（詳細は表 4.5 を参照）**を投入し、意図通りのドキュメントを識別できるか検証を行った。

**2. 評価方法**
採用候補である `multilingual-e5-small`（量子化版）を用いてドキュメントとクエリをベクトル化し、コサイン類似度を算出する。各クエリに対して、正解となるドキュメントが最も高いスコア（Top1）を獲得できるかを確認する。

**3. 実験結果**
実験の結果を表 .ref {tbl:accuracy_test} に示す。

| 検索クエリ（意図） | Top1 (正解) | スコア | Top2 (不正解) | スコア |
| :--- | :--- | :--- | :--- | :--- |
| **履歴を書き換えて一直線にする**<br>(Rebase狙い) | **Git Rebase** | **0.8602** | Git Merge | 0.8410 |
| **履歴構造を維持したままマージ**<br>(Merge狙い) | **Git Merge** | **0.8588** | Git Rebase | 0.8534 |
| **ブラウザを閉じても残り続ける**<br>(LocalStorage狙い) | **LocalStorage** | **0.9017** | SessionStorage | 0.8951 |
| **タブを閉じた瞬間に破棄される**<br>(SessionStorage狙い) | **SessionStorage** | **0.8873** | LocalStorage | 0.8789 |
"表 4.5: 技術用語における文脈識別精度の検証結果" {#tbl:accuracy_test}

**4. 考察**
実験の結果、全てのクエリにおいて正解ドキュメントが1位にランク付けされた。
Gitの例では、「履歴」「統合」といった共通キーワードがある中で「書き換える」対「維持する」という動詞的なニュアンスを識別できており、ストレージの例でも「保存」という共通語に惑わされず「永続性」と「一時性」を正確に区別できている。
この結果より、`multilingual-e5-small` は軽量モデルでありながら、本システムが対象とするNotionブロックのテキストデータの検索において、実用上十分なセマンティック検索能力を有していることが確認できた。

##### 選定結論
以上の検証結果より、本システムの運用環境（サーバーレス環境）におけるリソース制約をクリアし、かつ十分な検索精度を提供可能な唯一の選択肢として、**`multilingual-e5-small`（量子化版）** を採用することとした。

### インデックスの構築戦略と最適化

生成された埋め込みベクトルを高速に検索するため、本システムでは HNSW (Hierarchical Navigable Small World) アルゴリズムを採用している。
HNSW は、スモールワールドグラフの特性を利用した階層的なグラフ構造を持つ近似最近傍探索（ANN）手法であり、高次元データに対しても対数オーダーの計算量で検索が可能である .cite{Malkov2018}。

本節では、検索精度と速度のバランスを最適化するためのパラメータ選定、およびサーバーレス環境におけるリソース制約を克服するための構築・デプロイ戦略について述べる。

#### パラメータの選定実験
HNSW の性能は、主に以下の3つのハイパーパラメータに依存する。

1. ** $M$ **: 各ノードがグラフ内で保持する接続（エッジ）の最大数。値を大きくすると検索精度（Recall）は向上するが、メモリ消費量と構築時間が増加する .cite{Malkov2018}。
2. **$ efConstruction $**: インデックス構築時の探索候補リストのサイズ。品質と構築時間のトレードオフに関与する。
3. ** $ efSearch $ **: 検索時の探索候補リストのサイズ。検索速度と精度のトレードオフを直接的に制御する。

本システムでは、検索精度（Recall@10）が 0.95 以上であることを要件とし、これを満たす最速のパラメータ設定を決定するための予備実験を行った。

**1. 実験条件**
* **データセット**: `multilingual-e5-small` の出力次元（384次元）に準拠した乱数ベクトル 10,000件。
    * 件数の根拠: 個人のナレッジベースにおける標準的な規模（約200ページ×50ブロック）を想定。
* **評価指標**: Recall（再現率）および平均検索時間（ms）。

**2. 実験結果と考察**
実験結果の一部を表 .ref {tbl:hnsw_benchmark} に示す。

| M | efConstruction | efSearch | Recall | Avg Time (ms) | 備考 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| 4 | 100 | 500 | 0.648 | 0.662 | 精度不足 |
| 16 | 100 | 380 | 0.951 | 1.512 | 目標達成 |
| **24** | **100** | **210** | **0.953** | **1.437** | **最適値（最速）** |
| 48 | 100 | 250 | 0.990 | 1.961 | 過剰スペック |

" 表 4.3: HNSWパラメータのベンチマーク結果（抜粋）" {#tbl:hnsw_benchmark}

実験の結果、Recall $\ge 0.95$ を達成する設定の中で、**$ M=24, efSearch=210 $** の組み合わせが最も高速（1.437ms）であったため、本システムではこの設定を採用した。

#### サーバーレス環境への適応（インデックス・ハイドレーション） {#sec:index_hydration}
最適なパラメータが決定したが、HNSW インデックスの構築（`initIndex` および `addPoint`）は、データ量 $N$ に対して $O(N \log N)$ の計算量を要する処理である。
AWS Lambda のようなサーバーレス環境において、リクエストやコンテナ起動のたびにこの構築処理を実行することは、コールドスタート時間の増大と CPU リソースの浪費を招くため現実的ではない。
また、実行時のファイルシステムが一時的（Ephemeral）であるため、静的ファイルへのパス解決が不安定になるという課題もある。

これらの問題を解決するため、本システムではインデックスを事前に構築し、アプリケーションコードの一部としてバンドルする「インデックス・ハイドレーション（Index Hydration）」機構を実装した。

1.  **ビルド時（Build Time）**:
    前処理パイプラインにおいて、決定したパラメータ（$ M=24 $ 等）を用いてインデックスを構築し、そのバイナリデータを **Base64 文字列** に変換して TypeScript のソースコードに直接埋め込む。

2.  **実行時（Runtime）**:
    アプリケーション起動時、埋め込まれたデータをデコードしてメモリ上に展開することで、計算コストの高い構築プロセスを完全にスキップする。

この戦略により、高度なベクトル検索機能と、サーバーレス環境に求められる高速な起動・応答性能の両立を実現している。

### Amplifyへの更新データのデプロイ

本システムでは、前処理パイプラインによって生成された検索インデックスおよびローカル保存されたメディアファイルを、本番環境へ反映させるため、GitHub と AWS Amplify を連携させた CI/CD（継続的デリバリー）パイプラインを構築した。

### GitHub 連携による自動デプロイ
AWS Amplify は、指定された GitHub リポジトリの特定のブランチ（本システムでは `main` ブランチ）を監視する Webhook 機能を備えている。
前処理パイプラインの実行が完了し、更新されたインデックスファイルおよび `public/` ディレクトリ内のメディアファイルが Git 経由でリモートリポジトリへプッシュされると、AWS Amplify はこれを即座に検知し、ビルドおよびデプロイプロセスを自動的に開始する。

この仕組みにより、開発者が AWS コンソールを直接操作することなく、ローカルでのデータ更新作業から数分以内に、最新の検索データが本番環境へ反映されるワークフローを実現した。

### 更新フローのまとめ
本システムにおけるデータ更新の全体フローは以下の通りである。

1.  **ローカル実行**: 開発者がローカル環境で前処理スクリプトを実行し、最新の Notion データを取得・ベクトル化し、インデックスを構築する。
2.  **コミットとプッシュ**: 生成されたインデックスおよび保存したメディアファイルを Git でコミットし、GitHub へプッシュする。
3.  **自動デプロイ**: AWS Amplify がリポジトリの変更を検知し、Next.js アプリケーションのビルドと公開を自動実行する。

このように、更新データをリポジトリへプッシュするだけで、Webサイト上の検索データが常に最新の状態に同期される仕組みを構築した。

## Webアプリケーション実行環境

!(90%)[Quarkdown](image/webExecutionEnv.png "Webアプリケーション実行環境の処理フロー") {#fig:webExecutionEnv}

.ref {fig:webExecutionEnv} に、Webアプリケーション実行環境における詳細な処理フローを示す。 本システムは、Next.js の App Router を基盤とし、静的コンテンツの配信と動的な検索処理を明確に分離したアーキテクチャを採用している。 処理は主に AWS Amplify 上で実行され、以下の3つの主要なフェーズで構成される。
1.  **初期表示とレンダリング戦略**
   ユーザーからのアクセスに対し、ビルド時に生成された静的なHTMLファイルを即座に配信する（SSG）。 Notionの各ブロックデータは、それぞれの種別（見出し、リスト、画像等）に応じて動的に選択された最適なReactコンポーネントによってレンダリングされており、Notion上の表現を忠実に再現している。
2.  **サーバーサイドにおける検索処理**
    ユーザーの検索アクションに対し、Next.js の Server Actions を用いてサーバーサイドで検索ロジックを実行する。 静的に配置されたインデックスファイルをメモリ上に展開（ハイドレーション）し、シングルトンパターンで管理された推論モデルを用いて、クライアントに負荷をかけることなく高速なベクトル検索を行う。
3.  **クライアントサイドにおける検索結果の可視化**
    検索結果として返却されたNotionブロックデータを、クライアントサイドで動的に描画する。 検索結果のハイライト表示やページ内スクロールなど、ユーザー体験を向上させるインタラクティブな機能を実装している。

次節より、各フェーズにおける技術的な詳細と実装上の工夫について述べる。

### 4.3.1 初期表示とレンダリング戦略
#### SSGによる初期画面の高速配信
Webアプリケーションの初期表示速度は、ユーザー体験（UX）を決定づける最も重要な要素の一つである。
本システムでは、Next.js の SSG (Static Site Generation) 機能を活用し、ビルド時に生成された静的ファイルを配信することでこの課題を解決している。
具体的には、アプリケーションの入り口となるホームページ（Home コンポーネント）において、前処理パイプラインで生成された pages-index.json を読み込む実装とした。
この JSON ファイルには、全ページのタイトル、最終更新日時、IDといったメタデータが事前に集約されている。
ユーザーがサイトにアクセスした際、これらのメタデータを含んだ生成済みの HTML を即座に返却する。これにより、ユーザーは待ち時間なしで即座に資料の一覧確認や検索操作を開始することができる。

#### Notionの各ブロックのコンポーネント化とレンダリング
Notion のページデータは単純な HTML 文字列ではなく、見出し・段落・リスト・画像・コードブロックといった「ブロック（Block）」と呼ばれるオブジェクトが再帰的にネストされた木構造として管理されている。
本システムでは、Notion 上のリッチな表現力と構造を Web ブラウザ上で忠実に再現するため、各ブロックの特性に最適化された React コンポーネント群を実装し、それらを動的にマッピングするレンダリングエンジンを構築した。

**1. ブロック種別に基づく動的コンポーネント選択**
各ブロックデータには、その役割を示す `type` プロパティ（例: `heading_1`, `to_do`, `code`, `file`）が含まれている。
本システムの実装においては、`getBlockElement` 関数がこの `type` プロパティを識別子として分岐処理を行い、対応する専用コンポーネント（例: `<Heading1Block>`, `<CodeBlock>`, `<FileBlock>`）を動的に返却する設計とした。
これにより、例えば `code` ブロックであればシンタックスハイライトに適した配色を適用し、`file` ブロックであればダウンロードリンクとアイコンを表示するなど、ブロックごとの機能要件を満たす UI 表現を実現している。

**2. リッチテキストの解析と装飾の再現**
Notion のテキストデータは、単なる文字列ではなく「リッチテキストセグメント（RichTextSegment）」の配列として保持されている。各セグメントには、太字（bold）、斜体（italic）、文字色（color）、リンク（href）といった装飾情報（Annotations）が付与されている。
本システムでは、汎用コンポーネント `<RichText />` を実装し、これらの装飾情報を解析して適切な CSS クラス（Tailwind CSS）や HTML タグに変換する処理を行っている。これにより、ユーザーが Notion 上で行った細かい文字装飾やリンク情報を損なうことなく Web ページ上に反映させている。

**3. 再帰的レンダリングによる階層構造の維持**
Notion の大きな特徴である「リストの入れ子」や「トグルリスト（Toggle List）」、「テーブル（Table）」といった深い階層構造を再現するため、レンダリング処理は再帰的に設計されている。
親ブロックのレンダリング処理（`renderContent` 関数）は、`children` プロパティとして子ブロックの配列を受け取り、内部で自身を再帰的に呼び出す構造となっている。
例えば、トグルブロック（`<ToggleBlock>`）は開閉状態を管理する内部状態（State）を持ちつつ、その子要素としてネストされたブロック群を展開する。この再帰的な仕組みにより、深さの制限なく複雑なドキュメント構造を正しく描画することを可能とした。

### 4.3.2 サーバーサイドにおける検索処理

#### Server Actionsを用いたベクトル検索の非同期実行

ユーザーが入力した検索クエリをベクトル化し、数千件のドキュメントと照合する処理は、CPU リソースを大きく消費する計算集約型のタスクである。これをクライアントサイド（ブラウザ）で実行することは、端末の動作遅延やバッテリー消費の増大を招くため実用的ではない。
本システムでは、Next.js の **Server Actions** 機能を採用し、これらの重い処理をサーバーサイドへオフロードしつつ、クライアントからは非同期関数として透過的に呼び出すアーキテクチャを構築した。
サーバーサイドでは、受け取ったテキストクエリに対し、.ref {sec:query_embedding} で述べるシングルトンインスタンスを用いてベクトル化を行い、.ref {sec:method} で示した「Webアプリケーション実行環境」のフローに従って近傍探索を実行する。

**1. API定義を不要とする型安全なデータ連携**
Server Actions は、サーバーサイドで実行される関数を、クライアントコンポーネントから通常の JavaScript 関数と同様にインポートして呼び出すことができる機能である。
本システムの実装（.ref {code:server_action}）において、`searchDocuments` 関数はファイルの冒頭で `"use server"` ディレクティブを宣言している。これにより、Next.js はビルド時に自動的に API エンドポイントを生成し、クライアントからの関数呼び出しを HTTP POST リクエスト（RPC: Remote Procedure Call）へと変換する。
この仕組みにより、開発者は明示的な API ルーティングや fetch 処理を記述することなく、型安全性（Type Safety）を保ったままサーバー側のロジックを実行できる。

**2. 計算負荷のオフロードと非同期処理**
検索実行時、クライアント（`PageNavigator`）は `await searchDocuments(query)` を呼び出し、サーバーからの応答を待機する。
サーバーサイドでは、受け取ったテキストクエリに対し、シングルトンインスタンスとしてメモリに常駐している埋め込みモデルを用いてベクトル化を行い、インデックス（HNSW）に対する近傍探索を実行する。
この一連の処理はすべてサーバー内の閉じた環境で行われるため、クライアントの UI スレッドをブロックすることはない。また、検索アルゴリズムの詳細やインデックスデータ自体もサーバー内に隠蔽されるため、セキュリティの観点からも堅牢な設計となっている。

```typescript "コード 4.3: Server Actionによる検索処理の実装（lib/actions/search.ts）" {#code:server_action}
"use server"; // Server Actionとして定義

import { SearchResult } from "../rag/vectorStore";
// ... imports

/**
 * ドキュメントを検索する（サーバーアクション）
 * クライアントから直接呼び出し可能だが、実体はサーバーで実行される
 */
export async function searchDocuments(
  query: string
): Promise<SearchResult[] | undefined> {
  try {
    // 1. 入力値の検証
    if (!query.trim()) {
      return [];
    }

    // 2. ローカルベクトルストアの初期化（シングルトン/キャッシュ利用）
    const store = await initializeLocalVectorStore();

    // 3. ベクトル検索の実行（埋め込み生成 -> HNSW探索）
    const results = await store.search(query, 10);
    
    return results;
  } catch (error) {
    console.error("Search error:", error);
    return undefined;
  }
}
```

#### クエリの埋め込みベクトルの生成 {#sec:query_embedding}
ユーザーから入力された自然言語の検索クエリを、インデックス内のデータと比較するためには、クエリ自体をパッセージ側と同一の次元を持つベクトルに変換（埋め込み）する必要がある。
本システムでは、外部のAPIサービスに依存せず、サーバーサイドで直接推論を行う構成をとっている。 .ref {sec:systemdetail} で述べた通り、サーバーレス環境におけるモデルの再ロードはレスポンス遅延の大きな要因となる。
これを防ぐため、.ref {code:embedding} に示す `LocalEmbeddings` クラスをシングルトンパターンで実装し、インスタンスおよびモデルをメモリ上にキャッシュすることで、2回目以降の推論を高速化した。

``` typescript "コード 4.2: 埋め込みベクトル生成クラス（LocalEmbeddings）" {#code:embedding}
export class LocalEmbeddings {
  private static instance: LocalEmbeddings | null = null;
  private modelName = "Xenova/multilingual-e5-small"; // 採用モデル

  // シングルトンインスタンスの取得
  static getInstance(): LocalEmbeddings {
    if (!LocalEmbeddings.instance) {
      LocalEmbeddings.instance = new LocalEmbeddings();
    }
    return LocalEmbeddings.instance;
  }

  // ベクトル化処理
  async embedQuery(text: string, isQuery: boolean = true): Promise<number[]> {
    if (!this.model) await this.initialize();

    // E5モデル特有のプレフィックス付与
    // query: 検索文用, passage: ドキュメント用
    let processedText = text.length > 512 ? text.substring(0, 512) : text;
    if (this.modelName.includes("e5")) {
      processedText = isQuery
        ? `query: ${processedText}`
        : `passage: ${processedText}`;
    }

    // 推論実行（平均プーリング・正規化）
    const result = await this.model(processedText, {
      pooling: "mean",
      normalize: true,
    });

    return Array.from(result.data as Float32Array);
  }
}
```



#### インデックス・ハイドレーション
サーバーサイドの検索ロジックを完結させるためのもう一つの重要な要素が、インデックスデータのメモリ展開である。
第 .ref {sec:index_hydration} 節で述べた「インデックス・ハイドレーション」に基づき、ビルド時に Base64 形式で埋め込まれたバイナリデータをデコードし、HNSWLib のインデックスとしてサーバーのメモリ上に即座に展開する。
この「モデルの常駐（.ref {sec:query_embedding}）」と「インデックスの即時展開（.ref {sec:index_hydration}）」の組み合わせにより、サーバーレス環境特有のコールドスタート問題を最小限に抑え、実用的な速度でのセマンティック検索を可能とした。

### 4.3.3 クライアントサイドにおける検索結果の可視化
ベクトル検索によって抽出されたドキュメントをユーザーに提示する際、単にページタイトルを列挙するだけでは、そのページのどの部分が検索意図に合致したのかを判断することが困難である。本節では、検索精度を視覚的に還元し、情報の再利用性を高めるためのUI実装について述べる。
#### 類似度に基づくランキング表示
サーバーサイドで計算されたコサイン類似度は、検索結果のスコアとしてクライアントへ返却される。本システムでは、このスコアが高い順（＝文脈的な関連性が高い順）に検索結果をソートして表示する。これにより、キーワードが完全一致しない場合でも、ユーザーは上位の結果を確認するだけで、意図に最も近い情報へ効率的にアクセスすることが可能となっている。
ヒット箇所の視覚的強調（ハイライト）
セマンティック検索においては、ページ内の特定の段落やリスト項目（ブロック）が検索クエリと類似していると判定される。本システムでは、ユーザーが検索結果を選択した際、ページ全体のレンダリングと同時に、検索ヒットの根拠となった特定のブロックを自動的に特定し、強調表示（ハイライト）する機能を実装した。
具体的には、該当するブロックの背景色を変更し、視覚的なインジケータを付与することで、長大なドキュメントの中であっても「回答が含まれる具体的な箇所」を一目で判別できるようにしている。これにより、ユーザーがページ内を再検索する手間を省き、目的の情報に即座に到達できる体験を提供している。
#### Notion へのシームレスなアクセス
本システムは Notion の外部ビューアとしての役割を果たす一方で、元データである Notion 本体との連携も重視している。検索結果の表示画面には、該当する Notion ページへの直接的なリンクを配置した。
ユーザーは、本システムで高速に情報の「場所」を特定した後、必要に応じてワンクリックでオリジナルの Notion ページを開き、データの編集や詳細なコンテキストの確認へ移行できる。この「検索・発見は本システム、編集・蓄積は Notion」というシームレスな導線設計により、既存のワークフローを損なうことなく高度な検索基盤を追加することを可能にした。

# 動作検証 {#sec:verification}

本章では、AWS Amplify Hosting 上に構築された本番環境における NotionFinder の動作検証結果について述べる。検証は、実際のモバイルおよび PC ブラウザからのアクセスを通じ、機能面とパフォーマンス面の両項目で実施した。

## 機能性の検証

### Notionコンテンツの再現性と表示
Notion API を通じて取得した非構造化データが、本番環境の Web アプリケーション上で意図通りレンダリングされているかを確認した。
検証の結果、テキストの装飾（太字、色、インラインリンク）に加え、画像、コードブロック、リストの階層構造、およびテーブルといったリッチなコンテンツが、Notion 上の表現を忠実に再現した状態で表示されることが確認できた。

### 検索およびハイライト機能
特定のキーワードを直接含まない自然言語クエリを投入し、セマンティック検索および UI の連動性を検証した。
検証の結果、コサイン類似度に基づいたランキングにより、意味的に関連性の高いドキュメントが上位に抽出されることを確認した。
また、検索結果の一覧から任意のアイテムをクリックした際、該当するページデータが非同期に取得され、ヒットの根拠となったブロックが自動的にビューポート中央へスクロールされるとともに、背景色がハイライトされる挙動を確認した。これにより、情報の「発見」から「特定」に至る一連のユーザー体験が、本番環境のネットワーク越しでも設計通りに動作していることを確認した。

## パフォーマンスと実用性の評価

### 検索応答時間とコールドスタートの課題
本システムの検索性能を評価するため、サーバーサイド（Server Actions）での処理時間を計測した。結果を .ref {tbl:performance} に示す。

| 実行状態 | 処理内容 | 平均応答時間 |
| :--- | :--- | :--- |
| **ウォームスタート** | 検索実行（クエリ推論 ＋ HNSW探索） | 約 1.2 秒 |
| **コールドスタート** | インスタンス起動 ＋ モデルロード ＋ インデックス展開 ＋ 検索 | 約 8.5 〜 12.0 秒 |
"表 5.1: 本番環境における検索応答時間の計測結果" {#tbl:performance}

検証の結果、サーバーのリソースが確保されている**ウォームスタート状態**では、平均 1.2 秒という、Web アプリケーションとして実用的な速度でセマンティック検索の結果を返却できることが確認された。これは、シングルトンインスタンスによるモデルのメモリ保持と、HNSW アルゴリズムによる高速なベクトル演算が有効に機能している成果といえる。

一方で、一定時間アクセスがない場合に発生する**コールドスタート**においては、応答までに 10 秒前後の時間を要する結果となった。
これは、AWS Amplify Hosting (AWS Lambda) において Next.js ランタイムが起動する時間に加え、約 100MB を超える機械学習モデルのロード、および Base64 形式からのインデックス・ハイドレーション処理（第 .ref {sec:index_hydration} 節）が CPU およびメモリに一時的な高負荷をかけていることが原因と考えられる。

### 評価のまとめ
動作検証の結果、本番環境における検索精度やリッチコンテンツの表示、およびページ内ハイライトといった機能面では極めて高い実用性を示した。
コールドスタートによる初動の遅延については、サーバーレス環境におけるリソース制約とモデルサイズに起因するトレードオフである。今後は、常時起動型のインスタンス（AWS App Runner 等）への移行や、モデルのさらなる軽量化、あるいはインデックスの外部データベース化（Vector DB の活用）が、さらなる体験向上のための改善策として挙げられる。

# おわりに {#sec:conclusion}

本研究では、Notion 内に蓄積されたデータを対象とし、文脈や意味に基づいた高度な検索を可能にするWebプラットフォーム「NotionFinder」の設計および開発を行った。
Notion 標準のキーワード検索における同義語や表記揺れへの対応の難しさ、および Notion AI のコストや公開範囲の制約といった課題に対し、埋め込みモデル（multilingual-e5-small）と HNSW アルゴリズムを組み合わせた独自のベクトル検索基盤を構築することで、情報の再利用性を大幅に向上させた。

システムの実装においては、Notion API を用いたデータの再帰的取得、メディアファイルの永続化、そしてサーバーレス環境の制約を克服するための「インデックス・ハイドレーション」など、実用性を重視した工夫を凝らした。
動作検証の結果、本番環境においてウォームスタート時で平均 1.2 秒という実用的な応答速度と、意図したドキュメントを的確に抽出する検索精度を確認することができた。

今後の展望として、本システムの**オープンソース（OSS）化**を予定している。
本研究で開発した検索基盤を広く公開することで、自分自身のナレッジ管理に留まらず、世界中の Notion ユーザーが自身のワークスペースに高度なセマンティック検索機能を容易に導入できる環境を整備したいと考えている。

また、具体的な活用シーンとして、**大学の授業や教育現場におけるナレッジベース**としての展開を強く望んでいる。
例えば、教員が Notion で管理している膨大な講義資料やレジュメ、過去の Q&A データを本システムを通じて公開することで、学生は曖昧な記憶に基づいたクエリからでも必要な情報に即座にアクセスできるようになる。これにより、情報の「場所」を探す時間を削減し、本来の学びや知的探求に充てる時間を最大化する、より効率的な学習環境の構築に貢献したい。

技術的な課題としては、動作検証で浮き彫りとなったコールドスタート時の遅延解消や、LLM を組み合わせた回答生成（RAG）への拡張、複数ワークスペースの統合検索などが挙げられる。

最後に、本システムの開発を通じて、蓄積された知識を「死蔵」させず、必要な時に必要な形で見つけ出せることの重要性を再確認した。NotionFinder が、知的生産活動における強力なパートナーとして、多くのユーザーに利用されるシステムへと発展していくことを期待している。

#! 謝辞

本研究を進めるにあたり、終始熱心なご指導と的確なご助言をいただいた指導教員の佐野彰先生に深く感謝申し上げます。先生の専門的な知見に基づいたアドバイス、ならびに多大なるご支援があったからこそ、本システムの開発および本論文の執筆を無事に完遂することができました。ここに心より感謝の意を表します。
