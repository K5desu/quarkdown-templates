.docname {卒業論文見本}
.doctype {paged}
.doclang {Japanese}
.theme {paperwhite} layout:{latex}

.pageformat size:{a4} margin:{1.5cm}
.pagemargin {bottomcenter}
    .text{}
.css
    .quarkdown h1 {font-size: 1.5rem !important;}
    .quarkdown h2 {font-size: 1.3rem !important;}
    .quarkdown h3 {font-size: 1.15rem !important;}
    .quarkdown h4 {font-size: 1.05rem !important;}
    /* Cross-reference: show Japanese style for section references */
    /* Top-level sections (no dot): 第1章 */
    .quarkdown .cross-reference[data-localized-kind="セクション"][data-location]:not([data-location*="."])::before {
        content: "第" attr(data-location) "章" !important;
    }
    /* Sub-sections (has dot): 第2.1節 */
    .quarkdown .cross-reference[data-localized-kind="セクション"][data-location*="."]::before {
        content: "第" attr(data-location) "節" !important;
    }

.var {author} {田代 圭梧}
.var {affiliation} {龍谷大学先端理工学部 数理・情報科学課程}
.var {id} {Y220010}
.var {maintitle1} {Notionデータを対象とした}
.var {maintitle2} {ベクトル検索システム}
.var {maintitle3} {「NotionFinder」の開発}
.var {subtitle}  {}

<!-- ナンバリング -->
.numbering
    - headings: 1.1
    - equations: (1.1)
    - figures: 1.1
    - tables: 1.1
    - citations: 1.1

<!-- タイトルページ -->
.function {titlepage}
    .whitespace height:{5cm}
    .column cross:{center}
        .text {2026年度 卒業論文}
        .whitespace height:{10mm}
        .text {.maintitle1} size:{large} weight:{bold}
        .text {.maintitle2} size:{large} weight:{bold}
        .text {.maintitle3} size:{large} weight:{bold}
        .text {.subtitle::otherwise {}} size:{normal}
    .whitespace height:{10cm}
    .column cross:{center} gap:{3mm}
        .text {.affiliation}
        .text {.id .author}
        .text {指導教員 佐野 彰}
    
<!-- 概要ページ -->
.function {abstractpage}
    abstract:
    .column cross:{center}
        .text {2026年度 卒業論文} size:{normal}
        .whitespace height:{5mm}
        .text {.maintitle1} size:{large} weight:{bold}
        .text {.maintitle2} size:{large} weight:{bold}
        .text {.maintitle3} size:{large} weight:{bold}
        .text {.subtitle::otherwise {}}
    .column cross:{end}
        .text {.affiliation}
        .text {.id .author}
        .text {指導教員 佐野 彰}
    .column cross:{center}
        .text {概要} size:{normal} weight:{bold}
    .abstract
    <<<
<!-- ここから論文データ -->
<!-- 概要 -->
.var {abstract}
    まだ
     <!-- 段落は空白行で -->
    書かない
.abstractpage {.abstract}

<!-- タイトルページ（ページ番号なし） -->
.titlepage

<!-- 目次（ページ番号なし） -->
.tableofcontents maxdepth:{2} includeunnumbered:{true} <!-- includebibliography:{true} -->

<!-- 4ページ目以降: 本文（ページ番号1から開始） -->
# はじめに {#sec:intro}
.resetpagenumber
.pagemargin {bottomcenter}
    .currentpage


## 研究背景
### Notionの普及と情報量の増大
近年、個人のタスク管理から企業のナレッジ共有に至るまで、クラウドベースのコラボレーションツールの利用が急速に拡大している。
中でも Notion Labs Inc. が提供する「Notion」は、ドキュメント作成、データベース管理、タスク管理などを一元化できる「オールインワン・ワークスペース」として、世界中で多くのユーザーを獲得している .cite{NotionAbout}。
Notion の柔軟なデータベース機能は、ユーザーによる自由度の高い情報蓄積を可能にする一方で、長期的な運用に伴いワークスペース内のデータ量は膨大かつ複雑化する傾向にある。

### 既存検索機能の課題
蓄積された膨大なデータから必要な情報にアクセスするためには、効率的な検索機能が不可欠である。
しかし、Notion に標準搭載されている検索機能は、基本的にキーワードマッチング（字句検索）に基づいている。
この手法は、クエリとドキュメント内の単語が完全に一致する場合においては有効であるが、同義語や表記揺れ、あるいは文脈的な意味の類似性を考慮することはできない「語彙の不一致（Vocabulary Mismatch）」の問題を抱えている .cite{IR_mismatch}。
そのため、ユーザーは正確なキーワードを記憶していなければ目的の情報に辿り着けず、情報の再利用性が著しく低下するという課題がある。

### Notion AI の制約
こうした課題に対し、Notion は大規模言語モデル（LLM）を活用した「Notion AI」を導入し、自然言語による質問応答機能を提供している。
しかし、Notion AI を制限なく利用するには追加のコストが発生するため、全てのユーザーにとって導入が容易なわけではない。
さらに重要な課題として、Web共有（外部公開）における制約が挙げられる。
Notion AI は基本的にログインユーザーのワークスペース内での利用を前提としており、Notionで構築したナレッジベースをWebサイトとして外部公開し、そこで不特定多数の訪問者にAI検索を提供するといった柔軟な運用は困難である。

## 本研究の目的
本研究では、Notion 内に蓄積されたデータを対象とし、文脈や意味に基づいた検索（セマンティック検索）を可能にするWebプラットフォーム「NotionFinder」の設計および開発を行う。
具体的には、Notion API を通じて取得したデータをベクトル化し、ユーザーの検索クエリとの意味的な類似度を計算することで、キーワードが完全に一致しなくとも関連性の高いドキュメントを抽出するシステムを構築する。

本研究の主な目的は以下の2点である。

1.  **セマンティック検索の実現**：キーワード検索では拾いきれない、文脈や意図を汲んだ検索体験を提供し、情報の再利用性を向上させること。
2.  **Web共有可能な検索基盤の構築**：Notion 本体の認証や有料プランの制約に依存せず、外部公開されたWebアプリケーション上で、安価かつ高速に高度な検索機能を利用可能にすること。

次章以降では、関連技術の解説、NotionFinder のシステム設計、および実装と評価について述べる。

# システム概要 {#sec:method}

## 問題設定
.ref {eq:min} の最小化問題を考える：

$ \min_{x \in \mathbb{R}^n} f(x) $ {#eq:min}

ここで $ f(x) $ は連続微分可能な関数とし、勾配降下法（Gradient Descent）は次式 .ref {eq:grad} で表される。

$ x_{k+1} = x_k - \eta_k \nabla f(x_k) $ {#eq:grad}

ただし $ \eta_k $ は学習率である。

## 改良手法
本研究では、勾配の大きさに応じて動的に学習率を調整する「適応勾配法（Adaptive Gradient Method）」を提案する。  その概要を .ref {code:grad} に示す。

```python "アルゴリズム 1: Adaptive Gradient Method" {#code:grad}
# Adaptive Gradient Method
def adaptive_gradient(f, grad_f, x0, eta0, epsilon=1e-6, max_iter=1000):
    x = x0
    eta = eta0
    for k in range(max_iter):
        g = grad_f(x)
        if np.linalg.norm(g) < epsilon:
            break
        eta = eta0 / (1 + 0.1 * np.linalg.norm(g))
        x = x - eta * g
    return x
```

上記アルゴリズムでは、勾配ノルムに応じて学習率を減衰させることで、収束の安定性を高めている。
このアプローチは、Adam .cite{Manual} や RMSProp .cite{Masthersthesis} のような既存の適応学習率法と共通の思想を持つ（詳細は .ref {sec:discussion}）。


# 数値実験 {#sec:experiment}

## 実験条件
提案手法の有効性を確認するため、Rosenbrock 関数 .ref {eq:rosenbrock} .cite{Misc}

$ f(x, y) = (1 - x)^2 + 100(y - x^2)^2 $ {#eq:rosenbrock}

を対象として実験を行った。実験は、手順 .ref{fig:diagram} の方法を用いて .ref{tbl:params} のパラメータ設定で実施した。

.mermaid caption:{My Mermaid diagram.}
    flowchart TD
        A([Start]) --> B[Enter username and password]
        B --> C{Correct?}
        C -- Yes --> D[Redirect to dashboard]
        C -- No --> E[Show error message]
        D --> F([End])
        E --> F
<!--{#fig:diagram}-->

パラメータ設定を表 .ref {tbl:params} に示す。

| パラメータ | 値 | 説明 |
|------------|----|------|
|期点 $ (x_0, y_0) $ | (−1.2, 1.0) | 標準設定 |
|学習率 $ \eta_0 $ | 0.01 | 初期値 |
|最大反復回数 | 1000 | 収束条件まで |
"実験パラメータ設定" {#tbl:params}

# 結果 {#sec:result}

提案手法の結果を .ref {fig:bar} .ref {fig:xy} に示す。従来の勾配降下法に比べ、提案手法は初期段階での収束が速いことが確認できた。 .ref {sales-fig} は四半期別売上推移を示す。

.xychart caption:{四半期別売上推移}
    - type: line
    - x: ["Q1", "Q2", "Q3", "Q4"]
    - y: [10, 18, 25, 30]
<!--{#sales-fig}-->

.xychart caption:{"結果の嘘グラフ"} bars:{yes} x:{Months} y:{Revenue} yrange:{100..}
    - 250
    - 500
    - 350
    - 450
    - 400
    - 500
    - 600
<!--{#fig:bar}-->

.xychart caption:{"嘘グラフその2"}
    .repeat {100}
        .1::pow {2}::divide {100}
    
    .repeat {100}
        .1::logn::multiply {10}
<!--{#fig:line}-->


また、.ref {fig:bar} を .ref{fig:line} で Quarkdown 変換し第1、第2主成分による2次元平面へ射影することで .ref {fig:logo} が得られた。

!(50%)[Quarkdown](image/logo.png "Quarkdown icon") {#fig:logo}

# 考察 {#sec:discussion}

本手法は勾配の大きさに応じて学習率を調整するため、初期段階では大きく、収束近傍では小さくなる。
これにより、探索効率と安定性の両立が実現できた。
一方で、勾配が極端に小さい領域では更新幅が小さくなりすぎる問題が見られた。
この点は、下限値を設定することで改善可能である。

また、Adam などの手法が勾配の移動平均を用いるのに対し、本手法は勾配ノルムに基づく単純な調整のみを行うため、計算コストが軽いという利点がある。
今後は、ハイブリッド法や確率的勾配降下（SGD）との組み合わせを検討する。

# 結論 {#sec:conclusion}

本研究では、勾配ノルムに基づく動的学習率調整法を提案した。
理論的解析および数値実験の結果、提案手法は収束の安定性と速度の両面で従来法を上回ることが確認された。
今後は、大規模データセットへの応用やハイパーパラメータ自動調整への拡張を行う予定である。

<<<
#! 謝辞

本研究を進めるにあたり、指導をいただいた佐藤花子教授、ならびに実験協力をいただいた研究室の皆様に感謝申し上げる。

.bibliography {references.bib} style:{ieeetr}

<<<
#! 付録

